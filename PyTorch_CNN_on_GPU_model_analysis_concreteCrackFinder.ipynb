{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import xlwt \n",
    "from xlwt import Workbook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preparation\n",
    "class Concrete:\n",
    "    \n",
    "    def __init__(self, IMG_HEIGHT, IMG_WIDTH):\n",
    "        self.IMG_HEIGHT = IMG_HEIGHT\n",
    "        self.IMG_WIDTH  = IMG_WIDTH\n",
    "        self.POS = \"data_sets/concrete/Positive\"\n",
    "        self.NEG = \"data_sets/concrete/Negative\"\n",
    "        self.TESTING = \"PetImages/Testing\"\n",
    "        self.LABELS = {self.POS: 0, self.NEG: 1}\n",
    "        self.all_available_data = []\n",
    "        self.poscount = 0\n",
    "        self.negcount = 0\n",
    "   \n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_HEIGHT, self.IMG_WIDTH))\n",
    "                        self.all_available_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "\n",
    "                        if label == self.POS:\n",
    "                            self.poscount += 1\n",
    "                        elif label == self.NEG:\n",
    "                            self.negcount += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))\n",
    "\n",
    "        np.random.shuffle(self.all_available_data)\n",
    "        np.save(\"all_available_data_concrete.npy\", self.all_available_data)\n",
    "        print('Positive:',self.poscount)\n",
    "        print('Negative:',self.negcount)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set the Neural Net\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, IMG_HEIGHT, IMG_WIDTH):\n",
    "        '''\n",
    "        First inherit the nn.module class to use pytorch.\n",
    "        Then add the convulutional layers.\n",
    "        Do the flattening.\n",
    "        Then liner/dense layerse can be added accordingly.\n",
    "        '''\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        \n",
    "        self.IMG_HEIGHT = IMG_HEIGHT\n",
    "        self.IMG_WIDTH  = IMG_WIDTH\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "   \n",
    "        x = torch.randn(self.IMG_HEIGHT,self.IMG_WIDTH).view(-1,1,self.IMG_HEIGHT,self.IMG_WIDTH) # A random tensor is passed through the conv. layers once so that\n",
    "        self._to_linear = None                  # the size of the output of the last conv. layer can be found.\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "        \n",
    "\n",
    "    def convs(self, x):\n",
    "        '''\n",
    "        Applying max_pooling and using appropiate activation function for conv. layers\n",
    "        '''\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Reshaping after conv. layers accordingly \n",
    "        Then applying activation functions to the linear layers and the output layers.\n",
    "        '''\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        \n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, MODEL_NAME,  BATCH_SIZE, EPOCHS, test_X, test_y, testing_size, IMG_HEIGHT, IMG_WIDTH):\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.EPOCHS = EPOCHS\n",
    "        self.test_X = test_X\n",
    "        self.test_y = test_y\n",
    "        self.IMG_HEIGHT = IMG_HEIGHT\n",
    "        self.IMG_WIDTH  = IMG_WIDTH\n",
    "        self.size = testing_size        \n",
    "        self.MODEL_NAME = MODEL_NAME\n",
    "    \n",
    "    def fwd_pass(self, X, y, train=False):\n",
    "        '''\n",
    "        Passing the data for both training and testing\n",
    "        '''\n",
    "        if train:\n",
    "            net.zero_grad()\n",
    "        outputs = net(X)\n",
    "        matches  = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "        acc = matches.count(True)/len(matches)\n",
    "        loss = loss_function(outputs, y)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return acc, loss\n",
    "    \n",
    "    \n",
    "    def fit(self, net, train_X, train_y):\n",
    "        '''\n",
    "        Train the data, set HYPER_PARAMETERS(Epocsh, batch_size).\n",
    "        Set the optimizer    \n",
    "        '''\n",
    "        wb = Workbook()\n",
    "        sheet_name = self.MODEL_NAME \n",
    "        s1 = wb.add_sheet(sheet_name)\n",
    "        s1.write(0,0,'Training Accuracy')\n",
    "        s1.write(0,1,'Test Accuracy')\n",
    "        s1.write(0,2,'Training Loss')\n",
    "        s1.write(0,3,'Test Loss')\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            for i in tqdm(range(0, len(train_X), self.BATCH_SIZE)):\n",
    "                batch_X = train_X[i:i+self.BATCH_SIZE].view(-1, 1, IMG_HEIGHT, IMG_WIDTH)\n",
    "                batch_y = train_y[i:i+self.BATCH_SIZE]\n",
    "\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                acc, loss = self.fwd_pass(batch_X, batch_y, train=True)\n",
    "            \n",
    "            random_start = np.random.randint(len(self.test_X)-self.size)\n",
    "            X, y = self.test_X[random_start:random_start+self.size], self.test_y[random_start:random_start+self.size]\n",
    "            with torch.no_grad():\n",
    "                val_acc, val_loss = self.fwd_pass(X.view(-1, 1, IMG_HEIGHT, IMG_WIDTH).to(device), y.to(device))\n",
    "            print(f\"Epoch  {epoch+1} :\\n\")\n",
    "            print(' Training Accuracy :', acc, '\\n', 'Test Accuracy :', val_acc, '\\n', 'Training Loss :', loss.item(), '\\n', 'Test Loss :', val_loss.item())   \n",
    "            s1.write(epoch+1,0, round(float(acc),2))\n",
    "            s1.write(epoch+1,1, round(float(val_acc),2))\n",
    "            s1.write(epoch+1,2, round(float(loss), 4))\n",
    "            s1.write(epoch+1,3, round(float(val_loss), 4))\n",
    "            filename = self.MODEL_NAME +'.xls'\n",
    "            wb.save(filename) \n",
    "            \n",
    "            \n",
    "    def predict(self, net, X_pred):\n",
    "        X_pred = X_pred.view(-1, 1, IMG_HEIGHT, IMG_WIDTH)\n",
    "        X_pred = X_pred.to(device)\n",
    "        outputs = net(X_pred)\n",
    "        prediction = torch.argmax(outputs)\n",
    "        if prediction == 0:\n",
    "            print('There is a crack')\n",
    "        else:\n",
    "            print('There is no crack')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n",
      "Neural Net Features :  Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=10368, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "Optimizer Features :  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Loss Function :  MSELoss()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Data Set : 40000\n",
      "Training Set Ratio [%] : 10.0\n",
      "Size of the Train Set : 36000  <---> Size of the Test Set : 4000\n",
      "\n",
      " HYPERPARAMETERS : \n",
      "Batch Size :  32\n",
      "# of Epochs :  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1125/1125 [00:59<00:00, 18.94it/s]\n",
      "  0%|▏                                                                                | 3/1125 [00:00<00:37, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 :\n",
      "\n",
      " Training Accuracy : 0.96875 \n",
      " Test Accuracy : 0.96 \n",
      " Training Loss : 0.03585147112607956 \n",
      " Test Loss : 0.033420778810977936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1125/1125 [00:49<00:00, 22.96it/s]\n",
      "  0%|▏                                                                                | 3/1125 [00:00<00:46, 24.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 :\n",
      "\n",
      " Training Accuracy : 0.9375 \n",
      " Test Accuracy : 0.99 \n",
      " Training Loss : 0.025847282260656357 \n",
      " Test Loss : 0.008279291912913322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████▎                                  | 631/1125 [00:29<00:22, 22.25it/s]"
     ]
    }
   ],
   "source": [
    "##### Main Code Here #####\n",
    "    \n",
    "# Loading the data, if data is already prepared once, just load it. Once the data is prepared, save it and turn the flag to False\n",
    "REBUILD_DATA = True # set to true to one once, then back to false unless you want to change something in your training data.\n",
    "\n",
    "IMG_HEIGHT = 100 # Set the image size IMG_HEIGHT x IMG_WIDTH pixel\n",
    "IMG_WIDTH  = 100\n",
    "if REBUILD_DATA:\n",
    "    concrete = Concrete(IMG_HEIGHT, IMG_WIDTH)\n",
    "    concrete.make_training_data()\n",
    "    \n",
    "all_available_data = np.load(\"all_available_data_concrete.npy\", allow_pickle=True)\n",
    "\n",
    "### Define a device to start GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # you can continue going on here, like cuda:1 cuda:2....etc. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")\n",
    "\n",
    "### Connecting the Neural Net to the GPU. Choosing the loss function, and optimizer parameters\n",
    "LEARNING_RATE = 0.001\n",
    "net = Net(IMG_HEIGHT, IMG_WIDTH).to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "print('Neural Net Features : ',net)\n",
    "print('Optimizer Features : ',optimizer)\n",
    "print('Loss Function : ', loss_function)\n",
    "    \n",
    "### Seperating features and labels, normalizing the data\n",
    "X = torch.Tensor([i[0] for i in all_available_data]).view(-1,IMG_HEIGHT,IMG_WIDTH)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in all_available_data])\n",
    "\n",
    "### Splitting the data as training and testing data\n",
    "VAL_PCT = 0.1  # Test set ratio\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "\n",
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print('Size of the Data Set :', len(all_available_data))\n",
    "print('Training Set Ratio [%] :', 100 * VAL_PCT)\n",
    "print('Size of the Train Set :', len(train_X), ' <---> Size of the Test Set :', len(test_X))\n",
    "\n",
    "### Training HYPERPARAMETERS\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "testing_size =  100 # len(test_X) -1\n",
    "#MODEL_NAME = f\"model-{int(time.time())}\"\n",
    "\n",
    "#for batch in BATCH_SIZE:\n",
    "batch = BATCH_SIZE\n",
    "MODEL_NAME = f\"model-Batch{int(batch)}-{int(time.time())}\"  # gives a dynamic model name, to just help with things getting messy over time. \n",
    "\n",
    "print('\\n HYPERPARAMETERS : ')\n",
    "print('Batch Size : ', batch)\n",
    "print('# of Epochs : ', EPOCHS)\n",
    "\n",
    "model = Model(MODEL_NAME, batch, EPOCHS, test_X, test_y, testing_size, IMG_HEIGHT, IMG_WIDTH)\n",
    "model.fit(net, train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### Data Visualization #####\n",
    "import pandas as pd\n",
    "\n",
    "columns = ['Training Accuracy', 'Test Accuracy', 'Training Loss', 'Test Loss' ]\n",
    "results_df = pd.read_excel(f\"model-Batch{int(batch)}-{int(time.time())}.xls\")\n",
    "results_df.columns = columns\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[['Training Accuracy','Test Accuracy']].plot(grid=True)\n",
    "results_df[['Training Loss','Test Loss']].plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"data_sets/concrete/Predict/0.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_sets/concrete/Predict/0.jpg\"\n",
    "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "X_pred = torch.Tensor(img).view(-1,IMG_HEIGHT,IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = X_pred/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(MODEL_NAME, batch, EPOCHS, test_X, test_y, testing_size, IMG_HEIGHT, IMG_WIDTH)\n",
    "model.predict(net, X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data_sets/concrete/Predict/1.jpg\"\n",
    "img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "X_pred = torch.Tensor(img).view(-1,IMG_HEIGHT,IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
